[
  {
    "page": 1,
    "text": "  \n \n \n \n \n \n \n \n \n \n \n \n  \nCP 1241"
  },
  {
    "page": 2,
    "text": " \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nAI Opportunities Action Plan \nPresented to Parliament  \nby the Secretary of State for Science, Innovation and Technology \nby Command of His Majesty \n \nJanuary 2025 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCP 1241 \n "
  },
  {
    "page": 3,
    "text": " \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n© Crown copyright 2025 \nThis publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated. \nTo view this licence, visit nationalarchives.gov.uk/doc/open-government-licence/version/3. \nWhere we have identified any third party copyright information you will need to obtain permission from the \ncopyright holders concerned. \nThis publication is available at www.gov.uk/official-documents. \nAny enquiries regarding this publication should be sent to us at aiactionplan@dsit.gov.uk. \nISBN 978-1-5286-5362-6 \nE03258815 01/25 \nPrinted on paper containing 40% recycled fibre content minimum. \nPrinted in the UK by HH Associates Ltd. on behalf of the Controller of His Majesty’s Stationery Office . "
  },
  {
    "page": 4,
    "text": "AI Opportunities Action Plan \n3 \nContents \nContents __________________________________________________________________ 3 \nForeword by the Secretary of State for Science, Innovation and Technology _____________ 4 \nThe opportunity ____________________________________________________________ 5 \n1. Lay the foundations to enable AI ____________________________________________ 7 \n1.1 Building sufficient, secure and sustainable AI infrastructure ______________________ 7 \n1.2 Unlocking data assets in the public and private sector __________________________ 9 \n1.3 Training, retaining, and attracting the next generation of AI scientists and founders __ 10 \n1.4 Enabling safe and trusted AI development and adoption through regulation, safety and \nassurance ______________________________________________________________ 13 \n2. Change lives by embracing AI ____________________________________________ 16 \n2.1 AI Adoption is core to delivering the government's missions ____________________ 16 \n2.2 Adopt a “Scan → Pilot → Scale” approach in government ______________________ 17 \n2.3 Enable public and private sectors to reinforce each other ______________________ 19 \n2.4 Address private-sector-user-adoption barriers _______________________________ 19 \n3. Secure our future with homegrown AI _______________________________________ 21 \nConclusion _______________________________________________________________ 24 \n \n \n  "
  },
  {
    "page": 5,
    "text": "AI Opportunities Action Plan \n4 \nForeword by the Secretary of State for \nScience, Innovation and Technology \nToday, Britain is the third largest AI market in the world. We are home to an extraordinary array \nof global talent and pioneering AI firms like Google DeepMind, ARM, and Wayve. But despite \nour record of scientific discovery – from Alan Turing on algorithms and general-purpose \ncomputing to Tim Berners-Lee’s World Wide Web – the UK risks falling behind the advances in \nArtificial Intelligence made in the USA and China.   \nIn this next phase of AI development, we want Britain to step up; to shape the AI revolution \nrather than wait to see how it shapes us. Because we believe Britain has a particular \nresponsibility to provide global leadership in fairly and effectively seizing the opportunities of \nAI, as we have done on AI safety. That is why one of my first acts as Secretary of State was to \ncommission Matt Clifford to devise an AI Opportunities Action Plan for the British government.  \nThis plan shows how we can shape the application of AI within a modern social market \neconomy. We will do so by working closely with the world’s leading AI companies, Britain’s \nworld leading academics and entrepreneurs, and those talented individuals keen to start-up \nand scale-up their businesses here. Our ambition is to shape the AI revolution on principles of \nshared economic prosperity, improved public services and increased personal opportunities so \nthat:  \n• AI drives the economic growth on which the prosperity of our people and the \nperformance of our public services depend;  \n• AI directly benefits working people by improving health care and education and how \ncitizens interact with their government; and   \n• the increasing of prevalence of AI in people’s working lives opens up new opportunities \nrather than just threatens traditional patterns of work.   \nAcross government, we have already taken decisive action to support the AI sector and take \ndown the barriers to growth. Our transformative planning reforms will make it easier to build the \ndata centres that are the engines of the AI age. Skills England will help ensure that British \npeople are prepared for jobs in the AI-powered industries of tomorrow. The Digital Centre of \nGovernment I have created in my Department will drive forward the technological \ntransformation of the state, ensuring that public services offer citizens the same seamless \nexperience they can find in the private sector. \nThe recommendations in this plan are unapologetic in their ambition; Government must be the \nsame. Delivering our AI vision for Britain requires lots of hard work, some tough choices, and a \ncommitment to real partnership between public and private sectors. There’s no time to waste. \nToday, we have set out how we will rise to the challenge.  \nThe Rt Hon Peter Kyle MP, Secretary of State for Science, Innovation and Technology  "
  },
  {
    "page": 6,
    "text": "AI Opportunities Action Plan \n5 \nThe opportunity \nAI capabilities are developing at an extraordinary pace. If this continues, artificial intelligence \n(AI) could be the government’s single biggest lever to deliver its five missions, especially the \ngoal of kickstarting broad-based economic growth. It is hard to imagine how we will meet the \nambition for highest sustained growth in the G7 – and the countless quality-of-life benefits that \nflow from that – without embracing the opportunities of AI. \nAny national AI plan needs to be founded on a realistic assessment of the country’s strengths \nand weaknesses. Fortunately, the UK has solid – and in places genuinely world-leading – \nfoundations on which to build: \n• Strong fundamental AI research, and high-quality research and engineering talent \ncoming out of our universities, which are some of the best in the world for AI. \n• A vibrant startup and scaleup scene, with an increasingly skilled and experienced \nentrepreneurial workforce and growing quantities of sophisticated capital available for \nambitious companies. \n• Leading frontier AI companies in London, including Google DeepMind’s headquarters, \nsignificant OpenAI, Anthropic, Microsoft and Meta AI offices, as well as emerging local \nwinners – such as Wayve, the autonomous vehicle company. \n• Global leadership on AI safety and governance via the AI Safety Institute, and a \nproportionate, flexible regulatory approach. \nThese are all crucial prerequisites to making the most of AI opportunities; without them, the \nambition in this plan would not be credible. However, we cannot be complacent: to remain a \nworld leader we need to lead in both building and using AI. Our goal should be a thriving \ndomestic AI ecosystem, with serious players at multiple layers of the “AI stack” and widespread \nuse of AI products and services across the economy. \nThe UK’s starting point makes this aspiration plausible, but achieving it will require bold and \nvisionary action. The government must:  \n• Invest in the foundations of AI: We need world-class computing and data \ninfrastructure, access to talent and regulation (Section 1). \n• Push hard on cross-economy AI adoption: The public sector should rapidly pilot and \nscale AI products and services and encourage the private sector to do the same. This \nwill drive better experiences and outcomes for citizens and boost productivity (Section \n2). \n• Position the UK to be an AI maker, not an AI taker: As the technology becomes more \npowerful, we should be the best state partner to those building frontier AI. The UK \nshould aim to have true national champions at critical layers of the AI stack so that the \nUK benefits economically from AI advancement and has influence on future AI’s values, \nsafety and governance (Section 3). "
  },
  {
    "page": 7,
    "text": "AI Opportunities Action Plan \n6 \nThis Action Plan is made up of three sections – one for each of these goals. There are detailed \nrecommendations in each. In making them, I have tried to draw consistently on a small number \nof core principles:  \n• Be on the side of innovators: In every element of the Action Plan, the government \nshould ask itself: does this benefit people and organisations trying to do new and \nambitious things in the UK? If not, we will fail to meet our potential. \n• Invest in becoming a great customer: Government purchasing power can be a huge \nlever for improving public services, shaping new markets in AI, and boosting the \ndomestic ecosystem. But doing this well is not easy – it will require real leadership and \nradical change, especially in procurement. \n• Crowd in capital and talent: The UK is a medium-sized country with a tight fiscal \nsituation. We need the best talent around the world to want to start and scale \ncompanies here. If we do that, the best investors globally will want to deploy capital here \n– both into our startups and our AI infrastructure.  \n• Build on UK strengths and catalytic emerging areas: The UK has strong companies in \nthe AI application and integration layers that are well positioned to grow. We also have \nemerging areas of research and engineering strength – particularly in AI for science and \nrobotics – that could have a transformational impact across the economy, advance AI \nand unlock further innovation.  \nNo one can say with certainty what AI will look like a decade from now. My judgement is that \nexperts, on balance, expect rapid progress to continue. The risks from underinvesting and \nunderpreparing, though, seem much greater than the risks from the opposite. Even if AI \nprogress slows, we will see large benefits from deploying today’s frontier capabilities and \ninvesting in our infrastructure and talent base.  \nIf, however, capabilities continue to advance, having a stake in – and being the natural home \nof – advanced AI could be the difference between shaping the future of science, technology \nand work, or instead seeing these decisions made entirely outside our borders. This is a crucial \nasymmetric bet – and one the UK can and must make. \n  "
  },
  {
    "page": 8,
    "text": "AI Opportunities Action Plan \n7 \n1. Lay the foundations to enable AI \n1.1 Building sufficient, secure and sustainable AI infrastructure \nThe foundation of the last decade of AI progress has been an extraordinary and sustained \ninvestment in computational power (often called “compute”). AI requires data centres that \nhouse the large and complex computers that are used to train AI models and to run ‘inference’ \n(where AI is used to complete tasks and answer queries). \nOf course, the UK does not need to own or operate all the compute it will need. Indeed, only a \nsmall fraction of our needs will be through such compute (though this fraction is important). A \ndecade from now the economy will almost certainly be more computationally intensive: new \nhigh-skill jobs and compute-adjacent industries will have been created and access to compute \nwill be a key pillar of economic security. Countries that enable the build out of AI infrastructure \nwill reap benefits through increased economic growth, the reinvigoration of former industrial \nsites and ownership of critical strategic assets.  \nThe availability of powerful computing resources sends an important signal to academic, \ntechnical and entrepreneurial talent and is a critical ingredient of innovation. We should expect \nenormous improvements in computation over the next decade, both in research and \ndeployment. Having this “learning by doing” happen in the UK is crucial if we want the \nindustries of the future to be built here. \nThe government must therefore secure access to a sufficient supply of compute. There is no \nprecise mechanism to allocate the proportions, but it should consist of:  \n• Sovereign AI compute, owned and/or allocated by the public sector, will enable the UK \nto quickly and independently allocate compute to national priorities. For example, we \nneed the ability to: drive mission-focused AI research; empower academics and startups \nto train AI models; and ensure access to AI compute for critical services in times of \nmarket disruption. Sovereign AI compute will almost certainly be the smallest \ncomponent of the UK’s overall compute portfolio. NB: this review has not considered the \nrequirements of non-AI high-performance computing, for which there is already a well-\nestablished case, including the need to deliver an exascale capability. Government \nshould seek to resolve this as soon as possible, noting that these systems will play a \ncrucial role in supporting AI science and research.  \n• Domestic compute, that is based within the UK but privately owned and operated and \nthat will position the UK as a leading AI economy and ensure the UK’s economic \nsecurity. Due to the criticality of compute for AI, domestic compute will create spillover \nbenefits in the form of jobs, investment and new, AI based, service businesses. In this \npart of the portfolio, crowding in private and international capital is critical. \n• International compute, accessed via reciprocal agreements and partnerships with like-\nminded partners, to give the UK access to complementary capabilities and facilitate joint "
  },
  {
    "page": 9,
    "text": "AI Opportunities Action Plan \n8 \nAI research in areas of shared interest. We should proactively develop these \npartnerships, while also taking an active role in the EuroHPC Joint Undertaking.  \nTo achieve this, government should: \n1. Set out, within six months, a long-term plan for the UK’s AI infrastructure needs, \nbacked by a 10-year investment commitment. Building a world class AI compute \necosystem requires a clear objective and long-term capability and expertise. \nGovernment should consider what the most appropriate delivery body is for large scale \nresearch infrastructure that is delivered in partnership with universities and industry. We \nhave pockets of deep academic expertise in this space, such as at Edinburgh, Bristol \nand Cambridge universities, and we should draw on this. A credible plan will consider \nemerging compute technologies, include investment in software, skills, and wider high-\nperformance computing capabilities to complement our AI compute and enable AI for \nscience. \n2. Expand the capacity of the AI Research Resource (AIRR) by at least 20x by 2030 – \nstarting within 6 months. The AIRR should evolve into a set of mission-oriented \nclusters that bring together compute, data, and talent to pursue frontier AI research and \nother national priorities. Expansion by at least 20x by 2030 would ensure the AIRR \nenables the training of multiple AI models a year and provides an up to date research \ncapability.1 Given trends in hardware performance, this would not mean a 20x increase \nin investment if the government procures smartly.2 Such expansion is needed to keep \nup with the expected increases in computing power that we should assume will be \nneeded for AI workloads. This is unlikely to slow down; we need to “run to stand still”. As \npart of this, government should ensure that the public compute ecosystem hosts a \nrange of hardware providers to avoid vendor lock-in and ensure value for money.  \n3. Strategically allocate sovereign compute by appointing mission-focused “AIRR \nprogramme directors” with significant autonomy. These could be modelled after the \nDefense Advanced Research Projects Agency (DARPA) or the Advanced Research and \nInvention Agency (ARIA) to quickly and independently provide large amounts of \ncompute to high-potential projects of national importance, operating in a way that is \nstrategic and mission driven. Allocation is an essential part of any compute strategy: \nspreading large amounts of compute thinly will have little impact. We will have to make \nchoices about when to subsidise compute and when to provide it at cost, recognising \nthat this could form part of an attractive offer to entrepreneurs and researchers deciding \nwhere to base themselves. \n4. Establish ‘AI Growth Zones’ (AIGZs) to facilitate the accelerated build out of AI \ndata centres. As AI infrastructure providers seek access to land and power, \ngovernments who move quickly and mirror the pace of growth and innovation in the AI \ndata centre market will be best placed to secure investment. AIGZs could introduce a \n \n1 Assumes compute requirements continue to grow at 4x per year. \n2 Assuming trends in hardware performance continue, by 2030 each pound spent on GPUs will buy 8x more \nFLOP and require 4x less power, therefore expanding AIRR by 20x would require much less than a 20x increase \nin investment. "
  },
  {
    "page": 10,
    "text": "AI Opportunities Action Plan \n9 \nstreamlined planning approvals process and accelerate the provisioning of clean power. \nThis is a major opportunity to crowd in private capital to boost our domestic compute \nportfolio and to build strategic partnerships with AI developers to work on shared AI and \nAI-enabled priorities. Government can also use AIGZs to drive local rejuvenation, \nchannelling investment into areas with existing energy capacity such as post-industrial \ntowns and coastal Scotland. Government should quickly nominate at least one AIGZ \nand work with local regions to secure buy-in for further AIGZs that contribute to local \nneeds. Existing government sites could be prioritised as pilots, including Culham \nScience Centre, the UK Atomic Energy Authority’s headquarters, which has access to \nsignificant power and land. Alongside this, government should consider other measures \nto accelerate buildout of data centres, such as offering central guidance, creating a \nbespoke planning use-class and considering the case for AI data centres to be eligible \nfor relevant relief schemes that incentivise private sector investment.   \n5. Mitigate the sustainability and security risks of AI infrastructure, while positioning \nthe UK to take advantage of opportunities to provide solutions. This should focus \nboth on secure private-sector compute as well as collaboration with the UK Intelligence \nCommunity. Government should also explore ways to support novel approaches to \ncompute hardware and, where appropriate, create partitions in national supercomputers \nto support new and innovative hardware. In doing so, government should look to \nsupport and partner with UK companies who can demonstrate performance, \nsustainability or security advancements.  \n6. Agree international compute partnerships with like-minded countries to increase \nthe types of compute capability available to researchers and catalyse research \ncollaborations. This should focus on building arrangements with key allies, as well as \nexpanding collaboration with existing partners like the EuroHPC Joint Undertaking. \n1.2 Unlocking data assets in the public and private sector \nTo fuel both frontier AI progress and high-quality AI applications, developers need access to \nhigh-quality data - the lifeblood of modern AI. Data that isn't in the training sets of current \nmodels and encodes new insights about the world is particularly valuable. Public data sets, \nincluding scientific data sets, may be extremely important in this context.  \nWe should seek to responsibly unlock both public and private data sets to enable innovation by \nUK startups and researchers and to attract international talent and capital. As part of this, \ngovernment needs to develop a more sophisticated understanding of the value of the data it \nholds, how this value can be responsibly realised, and how to ensure the preservation of public \ntrust across all its work to unlock its data assets. \nThe creation of the National Data Library (NDL) presents an enormous opportunity. As it \ndevelops the NDL, the government should: \n7. Rapidly identify at least five high-impact public data sets it will seek to make \navailable to AI researchers and innovators. Prioritisation should consider the "
  },
  {
    "page": 11,
    "text": "AI Opportunities Action Plan \n10 \npotential economic and social value of the data, as well as public trust, national security, \nprivacy, ethics, and data protection considerations. We should explore use of synthetic \ndata generation techniques to construct privacy-preserving versions of highly sensitive \ndata sets. Government data sets are a public asset, and careful consideration should be \ngiven to their valuation. \n8. Strategically shape what data is collected, rather than just making data available \nthat already exists. Government should look to collect data in strategically significant \nareas, building on existing UK strengths. For example, the NDL could build on the \nachievements of the UK Biobank to enhance research in areas such as disease \nrecognition and the prediction of health outcomes. The NDL should run open calls to \nreceive proposals from researchers and industry to propose new data sets. \n9. Develop and publish guidelines and best practices for releasing open government \ndata sets that can be used for AI, including on the development of effective data \nstructures and data dissemination methods. \n10. Couple compute allocation with access to proprietary data sets as part of an \nattractive offer to researchers and start-ups choosing to establish themselves in the UK \nand to unlock innovation. \n11. Build public sector data collection infrastructure and finance the creation of new \nhigh-value data sets that meet public sector, academia and startup needs. \nGovernment should identify how public data will be collected and its quality enhanced, \nincluding the use of AI-driven data cleansing tools to curate data sets stored across \ngovernment, making them suitable for AI developers and researchers.  \n12. Actively incentivise and reward researchers and industry to curate and unlock \nprivate data sets. In particular, the NDL should engage with UKRI to identify how the \ncreation of valuable high-quality data sets that support the research community could be \nbetter acknowledged via the Research Excellence Framework. Government should also \nexplore how to shape the market in data set curation, including contributions from the \nprivate sector. \n13. Establish a copyright-cleared British media asset training data set, which can be \nlicensed internationally at scale. This could be done through partnering with bodies that \nhold valuable cultural data like the National Archives, Natural History Museum, British \nLibrary and the BBC to develop a commercial proposition for sharing their data to \nadvance AI. \n1.3 Training, retaining, and attracting the next generation of AI \nscientists and founders \nIf we want the UK to have both world-class AI research and a world-leading AI application \necosystem, we need to be the natural home for elite talent. In the next five years, the UK must \nbe prepared to train tens of thousands of additional AI professionals across the technology "
  },
  {
    "page": 12,
    "text": "AI Opportunities Action Plan \n11 \nstack to meet expected demand and proactively increase its share of the world’s top 1,000 AI \nresearchers.   \nIn the long-term, government needs to create a deeper pool of AI skills and talent that will \nbuild, diffuse and use AI products across the economy.3 Setting a short-term target to train \ntens of thousands of AI professionals by 2030 will help bridge the estimated gap between \nsupply and demand.4 This would put the UK in step with countries like France, whose National \nAI Commission calculates that the number of French AI graduates would need to triple over the \nnext decade to match estimated demand.5 \nAs a priority first step, government should: \n14. Accurately assess the size of the skills gap. Current estimates are imprecise and \noutdated; the last government-funded AI labour market survey was in 2020 and the Unit \nfor Future Skills’ jobs and skills dashboard, while a step in the right direction, still uses \nsupply data from 2019.6 The success of the following recommendations depends on \naccurately understanding the skills gap, and so government must make efforts to come \nto a concrete and up-to-date number. \nOnce the size of the skills gap is confirmed, to reach this target over the next five years \ngovernment should: \n15. Support Higher Education Institutions to increase the numbers of AI graduates \nand teach industry-relevant skills. In 2022, 46,000 students graduated from an AI-\nrelevant higher education programme in the UK. While this is the highest in Europe, with \nGermany (32,000) second, the UK is behind Finland and others on a per capita basis \nand there remains unmet demand for skilled workers.7 Supporting universities to \ndevelop new courses co-designed with industry – such as the successful co-operative \neducation model of Canada's University of Waterloo, CDTM at the Technical University \nof Munich or France's CIFRE PhD model – and increasing their teaching and \nrecruitment capacity would help train the tens of thousands of AI professionals needed \nby 2030. \n16. Increase the diversity of the talent pool. Only 22% of people working in AI and data \nscience are women.8 Achieving parity would mean thousands of additional workers. The \nAI conversion courses have helped to diversify the AI pipeline, but only at the top end. \nGovernment should build on this investment and promote diversity throughout the \neducation pipeline. Interventions must be tailored – there is no one-size-fits-all \n \n3 Jeffrey Ding, ‘Technology and the Rise of Great Powers: How Diffusion Shapes Economic Competition ’, 2024 \n4 Based on internal DSIT estimates. \n5 French Government, ‘25 Recommendations for AI in France’, 2024 (accessed 15 October 2024) \n6 Ipsos Mori ‘Understanding the UK AI labour market’ (accessed 15 October 2024), 2020; Unit for Future Skills, \n‘Jobs and skills dashboard’, 2023 (accessed 15 October 2024)  \n7 Stanford AI Index, ‘AI Index Annual Report’, 2024 (accessed 15 October 2024) \n8 The Alan Turing Institute, ‘Report: Where are the women? Mapping the Gender Job Gap in AI’, 2021 (accessed \n15 October 2024) "
  },
  {
    "page": 13,
    "text": "AI Opportunities Action Plan \n12 \napproach. Hackathons and competitions in schools have proven effective at getting \noverlooked groups into cyber and so should be considered for AI.9 \n17. Expand education pathways into AI. Higher education is the most common pathway \ninto AI careers and will likely remain so at least until 2030.10 To meet the demands of \nthe labour market and the changing skills needs of the future, however, government \nshould encourage and promote alternative domestic routes into the AI profession – \nincluding through further education and apprenticeships, as well as employer and self-\nled upskilling. \n18. Launch a flagship undergraduate and master’s AI scholarship programme on the \nscale of Rhodes, Marshall or Fulbright for students to study in the UK. Open to a \ndiverse initial cohort of 100 scholars from the UK and abroad, the programme would \ncombine financial support, cohort building, industry co-investment, and placements in \ngovernment or private sector AI organisations. Potential scholars must show exceptional \npromise, but recognising the broad range of talents needed for success in AI, this could \nbe in a variety of fields, such as strong performance in a leading STEM competition (e.g. \nthe International Mathematical or Informatics Olympiads).  \n19. Ensure its lifelong skills programme is ready for AI. AI will continue to change the \nlabour market, though exactly how and when is unclear. What is certain is while some \njobs will be replaced by AI, many will be augmented – and an unknown number will be \ncreated. Government should ensure there are sufficient opportunities for workers to \nreskill, both into AI and AI-enabled jobs and more widely. The UK should also learn and \nadopt best practice from other countries who are preparing their skills systems for the \nlong-term impacts of AI. Singapore, for example, developed a national AI skills online \nplatform with multiple training offers. South Korea is integrating AI, data and digital \nliteracy throughout its education pipelines through an AI curriculum and a variety of \ntraining and education programmes. Skills England and the independent Curriculum and \nAssessment Review present an opportunity to consider the merit of such approaches in \nour system. \nAlongside these longer-term investments, the government’s priority should be to rapidly \nincrease the number of top AI research talents who work in the UK. These leading AI scientists \nand engineers are few in number and highly prized globally. The countries that attract them will \nplay an outsized role in the future of AI. It is not surprising that the US, which is the number \none destination for top talent, has also been at the forefront of recent AI breakthroughs.  \nInternational competition for top talent is fierce. The UK must go further than existing measures \nand take a more proactive approach at every stage of the talent pipeline. Though ambitious, \nthese efforts could yield large benefits for the UK if one individual founds the next DeepMind or \nOpenAI. \n \n9 Centre for Security and Emerging Technology, ‘U.S. High School Cybersecurity Competitions’, 2022 (accessed \n15 October 2024) \n10 Unit for Future Skills, ‘Jobs and skills dashboard’, 2023 (accessed 15 October 2024)  "
  },
  {
    "page": 14,
    "text": "AI Opportunities Action Plan \n13 \nWithin the next year, government should:  \n20. Establish an internal headhunting capability on a par with top AI firms to bring a \nsmall number of elite individuals to the UK. Government should build on the success \nof the AI Safety Institute in attracting top talent. This may include recruiting more people \ninto AISI, UK Sovereign AI or other public AI labs, as well as UK-based companies. \nOfficials will need flexibility to develop specific offers and provide wraparound support to \ntalent targets – recognising that to truly ‘headhunt’ talent the programme will need to be \nbacked by appropriate funding.  \n21. Explore how the existing immigration system can be used to attract graduates \nfrom universities producing some of the world’s top AI talent. Graduates from \nsome leading AI institutions, such as the Indian Institutes of Technology and (since \n2020) Carnegie Mellon University in the US, are not currently included in the High \nPotential Individual visa eligibility list. Government should take steps to develop new \npathways, and strengthen existing ones, to support these graduates. It should also \nexplore how best to address wider barriers like the cost and complexity of visas which \ncreate obstacles for startups and deter overseas talent from re-locating to the UK.11 \n22. Expand the Turing AI Fellowship offer. 15 new Turing AI Pioneer Fellowships should \nbe created for specialists in other sectors who wish to develop deep technical skills in \nAI. At the same time, funding for 25 more Turing AI Acceleration and AI World-Leading \nfellowships should be committed to maintain the current cohort size over the next three \nyears, as existing fellows graduate from the programme. \n1.4 Enabling safe and trusted AI development and adoption \nthrough regulation, safety and assurance \nThe UK’s current pro-innovation approach to regulation is a source of strength relative to other \nmore regulated jurisdictions and we should be careful to preserve this. \nWell-designed and implemented regulation, alongside effective assurance tools, can fuel fast, \nwide and safe development and adoption of AI. Regulators themselves have an important role \nin supporting innovation as part of their Growth Duty. Government must protect UK citizens \nfrom the most significant risks presented by AI and foster public trust in the technology, \nparticularly considering the interests of marginalised groups. That said, we must do this without \nblocking the path towards AI’s transformative potential.  \nIneffective regulation could hold back adoption in crucial sectors like the medical sector.12 But \nregulation, safety and assurance have the power to drive innovation and economic growth too, \nas shown by the success of regulatory sandboxes in supporting fintech startups13 and the \n \n11 Startup Coalition, ‘Startup Manifesto 2024’, 2024 (accessed 15 October 2024) \n12 NHS England, ‘AI Regulation’, 2022 (accessed 15 October 2024) \n13 Bank for International Settlements, ‘Regulatory sandboxes and fintech funding: evidence from the UK’, 2022 \n(revised 2023) (accessed 15 October 2024)  "
  },
  {
    "page": 15,
    "text": "AI Opportunities Action Plan \n14 \ndevelopment of the UK’s cyber security industry.14 Clear rules provide clarity to businesses so \nthey have the confidence to invest and bring new products and services to market.  \nThe government should: \n23. Continue to support and grow the AI Safety Institute (AISI) to maintain and \nexpand its research on model evaluations, foundational safety and societal \nresilience research. AISI is the first safety institute to have conducted pre-deployment \nevaluations of frontier models and its success is a significant and growing source of \ninternational influence for the UK. Continued investment is needed to ensure AISI \nretains its position as a world-leader and remains attractive to top AI safety researchers. \nIt is also essential to act quickly to provide clarity on how frontier models will be \nregulated. A top priority of any such regulation should be preserving the capability, trust \nand collaboration that the AISI has built up since its creation. \n24. Reform the UK text and data mining regime so that it is at least as competitive as \nthe EU. The current uncertainty around intellectual property (IP) is hindering innovation \nand undermining our broader ambitions for AI, as well as the growth of our creative \nindustries. This has gone on too long and needs to be urgently resolved. The EU has \nmoved forward with an approach that is designed to support AI innovation while also \nenabling rights holders to have control over the use of content they produce. The UK is \nfalling behind. \nIt is also essential that we act now to ensure sector regulators are fit for the age of AI. In \nparticular, government should: \n25. Commit to funding regulators to scale up their AI capabilities, some of which \nneed urgent addressing. Government should also ensure all sponsor departments \ndemonstrate how they are funding this capability within their budgets through the \nSpending Review process. \n26. Ensure all sponsor departments include a focus on enabling safe AI innovation in \ntheir strategic guidance to regulators. AI will touch every aspect of the economy and \nso it is essential that all regulators are prioritising understanding its impacts in their \ndomains and considering how best to encourage its safe adoption. \n27. Work with regulators to accelerate AI in priority sectors and implement pro-\ninnovation initiatives like regulatory sandboxes. These should be targeted in areas \nwith regulatory challenges but high-growth potential, such as products which integrate \nAI into the physical world like autonomous vehicles, drones and robotics. \n28. Require all regulators to publish annually how they have enabled innovation and \ngrowth driven by AI in their sector. To ensure accountability, this should include \ntransparent metrics such as timelines to publish guidance, make licence decisions and \nreport on resources allocated to AI-focused work. Even with these initiatives, individual \nregulators may still lack the incentives to promote innovation at the scale of the \n \n14 DSIT, ‘Cyber security sectoral analysis 2024’, 2024 (accessed 15 October 2024) "
  },
  {
    "page": 16,
    "text": "AI Opportunities Action Plan \n15 \ngovernment’s ambition. If evidence demonstrates that is the case, government should \nconsider more radical changes to our regulatory model for AI, for example by \nempowering a central body with a mandate and higher risk tolerance to promote \ninnovation across the economy. Such a body could have expertise and statutory powers \nto issue pilot sandbox licences for AI products that override sector regulations, taking on \nliability for all related risks. This approach could initially be explored and piloted for \nspecific AI applications at small scale.  \nAlongside investing in pro-innovation regulation, the government should: \n29. Support the AI assurance ecosystem to increase trust and adoption by:  \n• Investing significantly in the development of new assurance tools, including \nthrough an expansion to AISI’s systemic AI safety fast grants programme, to \nsupport emerging safety research and methods. \n• Building government-backed high-quality assurance tools that assess whether AI \nsystems perform as claimed and work as intended.  \nAs part of taking forward the recommendations in this Action Plan, government should: \n30. Consider the broader institutional landscape and the full potential of the Alan \nTuring Institute to drive progress at the cutting edge, support the government’s \nmissions and attract international talent. \n  "
  },
  {
    "page": 17,
    "text": "AI Opportunities Action Plan \n16 \n2. Change lives by embracing AI \n2.1 AI Adoption is core to delivering the government's missions \nThe adoption of high-performing, trustworthy AI at scale will be critical to the government \nfulfilling the five missions. AI should become core to how we think about delivering services, \ntransforming citizens' experiences, and improving productivity. As well as strengthening the \nfoundations - data, skills, talent, IP, and assurance measures set out above - government \nshould also focus on its role as a major user and customer of AI and how it uses its powers to \ncatalyse private sector adoption: \n \nThough we are still early in the development of the AI application layer – and all AI use should \nbe tailored appropriately to the specific setting or sector in which it will be deployed. For \nexample, AI use in health and care will raise different considerations than in advanced \nmanufacturing. Indeed there are already great examples of AI use-cases driving tangible \nbenefits across the private and public sectors: \n• Using AI assistants to do repetitive tasks better and faster, freeing up to 20% of an \nemployee’s time.15 For example, it is helping some teachers cut down the 15+ hours a \nweek they spend on lesson planning and marking in pilots.   \n• Drafting structured reports and forms with AI can cut final document production \ntimes by 20-80% in professional services.16 Trials are underway exploring how these \nmethods can save time for clinical practitioners in the NHS.  \n• Automated threat and anomaly detection is already being responsibly deployed by \npolice forces across the country and used to clean up social media. \n• Assessment and diagnosis can be improved through the use of AI. For example, \nthrough the £21m AI Diagnostics fund, DHSC is supporting the deployment of \ntechnologies in key, high-demand areas such as chest X-Ray and chest CT scans to \nenable faster diagnosis and treatment of lung cancer in over half of acute trusts in \nEngland. Assessments can be done better, cheaper, and more quickly across multiple \nsectors. We also anticipate that AI will be a useful tool for assessment in the education \nsector. For example, the Department for Education’s generative AI and rules-based \n \n15 Business leader interviews, August 2024 \n16 Business leader interviews, August 2024 "
  },
  {
    "page": 18,
    "text": "AI Opportunities Action Plan \n17 \nmarking tool showed 92% accuracy in a pilot with teachers on year 4 literacy work when \ndrawing from appropriately coded educational data and content.17 \n2.2 Adopt a “Scan → Pilot → Scale” approach in government \nWhile there are instances of AI being used well across the public sector, often they are at small \nscale and in silos. Scaling these successes is essential, but will require us to think differently \nabout procurement, especially if this activity is to support the domestic startup and innovation \necosystem. As the digital centre of government, DSIT should support public sector partners \nwhere needed to “move fast and learn things”.  \nGovernment should generally employ a flexible “Scan → Pilot → Scale” approach: \nSCAN – investing in building a deep and continually updated understanding of AI capabilities \nmapped to their highest impact challenges and opportunities. This will require: \n31. Appointing an AI lead for each mission to help identify where AI could be a \nsolution within the mission setting, considering the user needs from the outset.  \n32. A cross government, technical horizon scanning and market intelligence \ncapability who understands AI capabilities and use-cases as they evolve to work \nclosely with the mission leads and maximise the expertise of both. \n33. Two-way partnerships with AI vendors and startups to anticipate future AI \ndevelopments and signal public sector demand. This would involve government \nmeeting product teams to understand upcoming releases and shape development by \nsharing their challenges.  \nPILOT – rapidly developing prototypes or fast light-touch procurement to spin up pilots in high-\nimpact areas, robust evaluation and publishing results. This will require: \n34. Consistent use of a framework for how to source AI – whether to build in-house, \nbuy, or run innovation challenges – that evolves over time, given data, capability, \nindustry contexts and evaluation of what’s worked. Where appropriate, the \ngovernment should support open-source solutions that can be adopted by other \norganisations and design processes with startups and other innovators in mind. \n35. A rapid prototyping capability that can be drawn on for key projects where \nneeded, including technical and delivery resource to build and test proof of \nconcepts, leveraging in-house AI expertise, together with specialists in design \nand user experience. \n \n17 Department for Education, ‘Use Cases for Generative AI in Education - Building a proof of concept for \nGenerative AI feedback and resource generation in education contexts: Technical report’ , 2024 (accessed 03 \nDecember 2024) "
  },
  {
    "page": 19,
    "text": "AI Opportunities Action Plan \n18 \n36. Specific support to hire external AI talent. Creation of a technical senior civil servant \nstream, benchmarking of internal AI-related role pay to at least 75% of private-sector \nrate and a technical AI recruitment screening process.18 \n37. A data-rich experimentation environment including a streamlined approach to \naccessing data sets, access to language models and necessary infrastructure like \ncompute. \n38. A faster, multi-stage gated and scaling AI procurement process that enables easy \nand quick access to small-scale funding for pilots and only layers bureaucratic \ncontrols as the investment-size gets larger. Multi-staged \"Competitive Flexible \nProcedures\" should be encouraged,19 and startups compensated for the rounds they \nmake it through. \nSCALE – identifying successful pilots that can be applied in different settings to support \ncitizens (e.g. to reduce waiting lists or minimise time and cost to complete paperwork) and \nrolling them out beyond organisational boundaries. Scale is essential if AI is to have a \nmeaningful impact on productivity, effectiveness and citizen experience, as well as maximising \ngovernment spending power. Moreover, doing this well and procuring in a way that benefits \ninnovators is a powerful lever for upending the cliché that the UK is good at invention, but poor \nat commercialisation. It will require: \n39. A scaling service for successful pilots with senior support and central funding \nresource. The government should support a select number of proven pilots to scale – \nwith central finance and tools available to avoid fragmentation across systems and \nbudgets – and achieve up to national level reach.  \n40. Mission-focused national AI tenders to support rapid adoption across de-\ncentralised systems led by the mission delivery boards. An example of tendering to \nenable scale is the NHS’s AI Diagnostic Fund allocating £21 million to 12 imaging \nnetworks, covering 66 NHS trusts across England, significantly speeding up the roll out \nof AI diagnostic tools nationwide.20 However, these tenders should be designed to \nencourage new entrants, avoiding reliance on commercial frameworks where possible. \n41. Development or procurement of a scalable AI tech stack that supports the use of \nspecialist narrow and large language models for tens or hundreds of millions of \ncitizen interactions across the UK.  \n42. Mandating infrastructure interoperability, code reusability and open sourcing. The \nAI infrastructure choice at-scale should be standardised, tools should be built with \nreusable modular code components, and code-base open-sourcing where possible. \n \n18 Tony Blair Institute, ‘Governing in the Age of AI: A New Model to Transform the State’, 2024 (accessed 15 \nOctober 2024)  \n19 Cabinet Office, ‘Guidance: Competitive Tendering Procedures’, 2024 (accessed 15 October 2024) \n20 NHS England, ‘AI Diagnostic Fund’, 2024 (accessed 15 October 2024) "
  },
  {
    "page": 20,
    "text": "AI Opportunities Action Plan \n19 \n2.3 Enable public and private sectors to reinforce each other \nThe public and private sectors should play mutually reinforcing roles in AI adoption. To get the \nmost from working together, government should: \n43. Procure smartly from the AI ecosystem as both its largest customer and as a \nmarket shaper. Innovative AI suppliers from the UK and around the world should be \nengaged to support demand and encourage investment. Procurement contract terms \nshould set standards (e.g. quality), requirements, and best practice (e.g. performance \nevaluations). “Contemplation” clauses should be included in contracts to ensure the \ngovernment remains agile to a rapidly changing AI ecosystem by mandating that \ncontractors regularly assess and adopt newer technologies.  \n44. Use digital government infrastructure to create new opportunities for innovators. \nFor example, an approach akin to Jeff Bezos’s API mandate at Amazon could be \nadopted. This required all teams’ data and functionality to be exposed through APIs \n(Application Programme Interfaces). All standard documentation interactions, like \ncompliance or planning, could be done through APIs, to which companies could connect \ntheir own tools. Similarly, mandating e-Invoices from government suppliers could \nautomate billing, speed up payments and reduce fraud. \n45. Publish best-practice guidance, results, case-studies and open-source solutions \nthrough a single “AI Knowledge Hub” accessible to technical and non-technical \nusers across private and public sectors as a single place to access frameworks and \ninsights. \n46. In the next three months, the Digital Centre of Government should identify a \nseries of quick wins to support the adoption of the scan, pilot scale approach and \nenable public and private sector to reinforce each other. \n2.4 Address private-sector-user-adoption barriers  \nAI adoption could grow the UK economy by an additional £400 billion by 2030 through \nenhancing innovation and productivity in the workplace.21 Safe, effective and swift AI adoption \nhas the potential to enhance the international competitiveness of sectors of UK strength and \nunlock new growth opportunities across the whole economy, including for SMEs. To capture \nthe benefits of AI adoption across the private sector, the government should: \n47. Leverage the new Industrial Strategy. The development of a new Industrial \nStrategy presents an opportunity to drive collective action to support AI adoption \nacross the economy. The Industrial Strategy will need to set out how AI adoption can \nbest be supported in key industries, noting particular use cases that could boost \nproductivity and present a particular competitive advantage while also identifying \npossible regulatory barriers and specific skills needs that need to be addressed. DSIT \n \n21 Public First, ‘Google’s Impact in the UK 2023’, 2024 (accessed 15 October 2024) "
  },
  {
    "page": 21,
    "text": "AI Opportunities Action Plan \n20 \nand others with AI expertise within government can play a critical role in combining with \nthose who have a deep understanding of their sectors to engage business leaders, \nidentify high-potential use cases, co-design targeted interventions to promote them and \novercome barriers to adopting them. \n48. Appoint AI Sector Champions in key industries like the life sciences, financial \nservices and the creative industries to work with industry and government and \ndevelop AI adoption plans. \n49. Drive AI adoption across the whole country. Widespread adoption of AI can address \nregional disparities in growth and productivity. To achieve this, government should \nleverage local trusted intermediaries and trade bodies to support business leaders, and \nalso consider opportunities to accelerate AI adoption by working across supply chains. \nA particular focus should be put on supporting SMEs and the specific challenges they \nface. \n  "
  },
  {
    "page": 22,
    "text": "AI Opportunities Action Plan \n21 \n3. Secure our future with homegrown AI \nBy the end of the decade, having national champions at the frontier of AI capabilities may be a \ncritical pillar of our national and economic security. Government should use the full powers it \nhas available to ensure this happens. \nAI systems are increasingly matching or surpassing humans across a range of tasks. Today’s \nAI systems have many limitations, but industry is investing at a scale that assumes capabilities \nwill continue to grow rapidly. Frontier models in 2024 are trained with 10,000x more computing \npower than in 2019, and we are likely to see a similar rate of growth by 2029. If progress \ncontinues at the rate of the last five years, by 2029 we can expect AI to be a dominant factor in \neconomic performance and national security. \nMany of us have become familiar with the remarkable capabilities of large language models \nacross a broad set of domains. Leading AI companies continue to push this frontier, and we \nare also seeing stunning progress in other modalities, including breakthroughs in video and \nimage generation, robotics, mathematics, and scientific discovery. To take one example, \nDeepMind’s AlphaFold – which predicts protein structures – is estimated to have saved the \nequivalent of 400 million years of researcher time. We can imagine the impact on science, \nmedicine and the broader economy if we see this sort of success in other domains.  \nGiven the pace of progress, we will also very soon see agentic systems – systems that can be \ngiven an objective, then reason, plan and act to achieve it. The chatbots we are all familiar with \nare just an early glimpse as to what is possible.  \nThe economic consequences of continued progress in these areas could be enormous. Just as \nwith previous technological revolutions, the people and countries who make decisions about \nhow these systems operate and what values they reflect – including their approach to safety – \nwill have huge influence over our lives.  \nIf this is to benefit the UK we must be an AI maker, not just an AI taker: we need companies \nat the frontier that will be our UK national champions. \nWe have all the raw ingredients to make this possible. AI research and product development is \na UK strength rooted in world-class engineering talent coming out of our excellent universities \nand local AI winners such as DeepMind and Wayve. Our position between the US and Europe, \nand convenient time-zone, make the UK an ideal place for international founders to \ncollaborate.  \nSections 1 and 2 of this Action Plan above are critical to building on this. Section 1 covered the \npolicy and infrastructure needed for the growth of the domestic AI sector. Section 2 covered \nthe policies needed for widespread AI adoption – a necessary condition for a world-leading AI \napplication ecosystem.  "
  },
  {
    "page": 23,
    "text": "AI Opportunities Action Plan \n22 \nWe should assume that most advanced economies will soon be doing much of the above. If we \naspire to be one of the biggest winners from AI and drive national renewal, we need to go \nfurther. \nGiven the lead the current frontier firms enjoy, we cannot expect the market to solely \nunderwrite a new challenger, especially in the next two to three years. But government holds \ncritical levers for the next stage of AI development. Generating national champions will require \na more activist approach and something more akin to Japan’s MITI or Singapore’s Economic \nDevelopment Board in the 1960s, not the “invisible hand”. \nThe government must maximise its ambition and ensure the UK has national champions at the \nfrontier of economically and strategically important capabilities. This means government needs \nto: \n• Ensure that research and development of frontier AI capabilities takes place in the UK – \nboth in the current foundation model paradigm and in emerging spaces such as AI for \nscience, robotics, and “embodied AI”.  \n• Ensure that the UK maximises both its economic upside from and influence on these \ncapabilities as they advance. \nAchieving this will require bold, concerted and coherent action, using all the levers of the state \nto make the UK the best place in the world to build and scale frontier AI companies. While I \ndon’t want to understate how difficult this will be, I am confident that with the right focus and \nbacking, the UK can do this.  \nTo this end, the government should: \n50. Create a new unit, UK Sovereign AI, with the power to partner with the private \nsector to deliver the clear mandate of maximising the UK’s stake in frontier AI. \nPublic-private collaboration will be at the heart of this unit. It will support the private and \nacademic sectors in doing what they do best, with the ability to collaborate internationally, \ncreate joint ventures, as well as invest in, incubate and spin out AI companies – refining its \nstrategy and approach as the technology matures. \nTo achieve this, the unit must develop a clear position on which areas of AI research are \nstrategically important for the future of the technology and make concentrated bets in these \nareas. This could involve supporting entrepreneurs to create new companies, backing startups \nto scale or partnering with existing AI companies that are already at the frontier to maximise \nthe UK’s upside however the technology develops.  \nWith a clear and powerful mandate the unit will play a critical coordinating role, able to remove \nbarriers and make deals to maximise the UK’s chance of growing globally competitive national \nchampions. It will need to be able to draw on the resources of government to act quickly and \ndecisively. If it is to succeed, it will require support from other government organisations. \nEspecially important will be Innovate UK, which should make AI a top priority and support the \nunit through the funding it provides to promising start-ups.  "
  },
  {
    "page": 24,
    "text": "AI Opportunities Action Plan \n23 \nEarly tolerance for scientific and technical risk can be hugely valuable. For example, the unit or \nits public sector partners might join funding rounds or provide advanced market commitments \nto credible and ambitious startups in emerging fields of AI. AI for science is an area with the \npotential to be particularly important because of its economic value and security implications; \nthe UK’s existing talent strengths; and the particularly high value of the state’s assets in this \nspace.   \nThe use of these non-financial assets, alongside capital and procurement, will be critical to the \nunit’s offer. UK Sovereign AI should lead the delivery of a government offer to new and \nexisting frontier AI companies that includes: \n• Direct investment into companies, including promising start-ups as well as joint ventures \nwith other commercial partners. \n• Delivering appropriate sites for compute in the UK, including through AI Growth Zones, \nand international partnerships to guarantee compute access from appropriate allies.  \n• Packaging and providing responsible access to the most valuable UK-owned data sets \nand relevant research. \n• Supporting UK-based AI organisations working on national priority projects to bring in \noverseas talent and headhunting promising founders or CEOs (and their teams) by \nconvincing them to relocate to the UK. \n• Facilitating deep collaboration with the national security community. \nIn exchange, UK Sovereign AI should ensure economic upside from, and influence on, \ngovernance of frontier AI for the UK. \nAI may well be the most important technology of our time. Now is the moment to act boldly and \nwith vision so that the UK helps to shape AI’s course and our citizens’ share in its upside. \n  "
  },
  {
    "page": 25,
    "text": "AI Opportunities Action Plan \n24 \nConclusion  \nThe Action Plan I have set out will require the government to both take a long-term view and \ntake action immediately. It will need to commit to securing the physical infrastructure and \nhuman capital that will underpin all future AI developments. Government should also have the \nself-confidence and ambition to set an example for the rest of the economy. This will require a \nnovel approach involving close collaboration with industry to ensure the whole of society can \nbenefit from the opportunities offered by AI.  \nBusiness-as-usual is not an option. Instead, government will need to be prepared to absorb \nsome risk in the context of uncertainty.   \nThis will require a whole of government commitment, with senior and visible leadership and a \nrelentless focus on driving progress. \nThis is no small task. Nevertheless, the benefits are likely to be transformational, not just to \nsupport economic growth, but to people’s lives across the whole of the UK."
  },
  {
    "page": 26,
    "text": " \n \nE03258815 \nISBN 978-1-5286-5362-6  \nThis publication is available from: www.gov.uk/official-documents. \nIf you need a version of this document in a more accessible format, please email \nalt.formats@dsit.gov.uk. Please tell us what format you need. It will help us if you say what \nassistive technology you use. \n "
  }
]